{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bae\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Bae\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\Bae\\anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import csv\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time, os, json\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class_names = ['Normal', 'Almost Clear', 'Mild', 'Moderate', 'Severe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode = 'Training', transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_path = glob.glob(root_dir + '/*/crop/*.jpg')\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_path[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'Test':\n",
    "            return img, self.img_path[idx]\n",
    "        else:\n",
    "            dir_name = os.path.dirname(self.img_path[idx])\n",
    "            file_name = os.path.basename(self.img_path[idx])\n",
    "            json_full_path = os.path.join(os.path.join(dir_name[:-4], 'metadata'), file_name[:-4] + '.json')\n",
    "            data = json.load(open(json_full_path))\n",
    "            if 'iga_grade' in data['annotations'][0]['clinical_info']:\n",
    "                grade = class_names.index(data['annotations'][0]['clinical_info']['iga_grade'])\n",
    "            else:\n",
    "                grade = 0\n",
    "            return img, grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetCropped(Dataset):\n",
    "    def __init__(self, root_dir, mode = 'Training', transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_path = glob.glob(root_dir + '*.png')\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_path[idx]).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        if self.mode == 'Test':\n",
    "            return img, self.img_path[idx]\n",
    "        \n",
    "        else:\n",
    "            dir_name = os.path.dirname(self.img_path[idx])\n",
    "            label = dir_name.split('/')[-1]\n",
    "            grade = class_names.index(label)\n",
    "\n",
    "            return img, grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(244),\n",
    "#         transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=(0, 180)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(244),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SE Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, r=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels * r),\n",
    "            Swish(),\n",
    "            nn.Linear(in_channels * r, in_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.excitation(x)\n",
    "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MB Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    expand = 6\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first MBConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * MBConv.expand, 1, stride=stride, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_channels * MBConv.expand, in_channels * MBConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*MBConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * MBConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*MBConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sep Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConv(nn.Module):\n",
    "    expand = 1\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first SepConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * SepConv.expand, in_channels * SepConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*SepConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * SepConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * SepConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*SepConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=5, width_coef=1., depth_coef=1., scale=1., dropout=0.2, se_scale=4, stochastic_depth=False, p=0.5):\n",
    "        super().__init__()\n",
    "        channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
    "        repeats = [1, 2, 2, 3, 3, 4, 1]\n",
    "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
    "        kernel_size = [3, 3, 5, 3, 5, 5, 3]\n",
    "        depth = depth_coef\n",
    "        width = width_coef\n",
    "\n",
    "        channels = [int(x*width) for x in channels]\n",
    "        repeats = [int(x*depth) for x in repeats]\n",
    "\n",
    "        # stochastic depth\n",
    "        if stochastic_depth:\n",
    "            self.p = p\n",
    "            self.step = (1 - 0.5) / (sum(repeats) - 1)\n",
    "        else:\n",
    "            self.p = 1\n",
    "            self.step = 0\n",
    "\n",
    "\n",
    "        # efficient net\n",
    "        self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(3, channels[0],3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[0], momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.stage2 = self._make_Block(SepConv, repeats[0], channels[0], channels[1], kernel_size[0], strides[0], se_scale)\n",
    "        self.stage3 = self._make_Block(MBConv, repeats[1], channels[1], channels[2], kernel_size[1], strides[1], se_scale)\n",
    "        self.stage4 = self._make_Block(MBConv, repeats[2], channels[2], channels[3], kernel_size[2], strides[2], se_scale)\n",
    "        self.stage5 = self._make_Block(MBConv, repeats[3], channels[3], channels[4], kernel_size[3], strides[3], se_scale)\n",
    "        self.stage6 = self._make_Block(MBConv, repeats[4], channels[4], channels[5], kernel_size[4], strides[4], se_scale)\n",
    "        self.stage7 = self._make_Block(MBConv, repeats[5], channels[5], channels[6], kernel_size[5], strides[5], se_scale)\n",
    "        self.stage8 = self._make_Block(MBConv, repeats[6], channels[6], channels[7], kernel_size[6], strides[6], se_scale)\n",
    "\n",
    "        self.stage9 = nn.Sequential(\n",
    "            nn.Conv2d(channels[7], channels[8], 1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[8], momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        ) \n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear = nn.Linear(channels[8], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.stage8(x)\n",
    "        x = self.stage9(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _make_Block(self, block, repeats, in_channels, out_channels, kernel_size, stride, se_scale):\n",
    "        strides = [stride] + [1] * (repeats - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(in_channels, out_channels, kernel_size, stride, se_scale, self.p))\n",
    "            in_channels = out_channels\n",
    "            self.p -= self.step\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_b1(num_classes=5):\n",
    "    return EfficientNet(num_classes=num_classes,\n",
    "                        width_coef=1.0,\n",
    "                        depth_coef=1.1,\n",
    "                        scale=240/224,\n",
    "                        dropout=0.2,\n",
    "                        se_scale=4)\n",
    "\n",
    "def efficientnet_b2(num_classes=5):\n",
    "    return EfficientNet(num_classes=num_classes,\n",
    "                        width_coef=1.1,\n",
    "                        depth_coef=1.2,\n",
    "                        scale=260/224.,\n",
    "                        dropout=0.3,\n",
    "                        se_scale=4)\n",
    "\n",
    "def efficientnet_b3(num_classes=5):\n",
    "    return EfficientNet(num_classes=num_classes,\n",
    "                        width_coef=1.2,\n",
    "                        depth_coef=1.4,\n",
    "                        scale=300/224,\n",
    "                        dropout=0.3,\n",
    "                        se_scale=4)\n",
    "\n",
    "def efficientnet_b4(num_classes=5):\n",
    "    return EfficientNet(num_classes=num_classes,\n",
    "                        width_coef=1.4,\n",
    "                        depth_coef=1.8,\n",
    "                        scale=380/224,\n",
    "                        dropout=0.4,\n",
    "                        se_scale=4)\n",
    "\n",
    "def efficientnet_b5(num_classes=5):\n",
    "    return EfficientNet(num_classes=num_classes,\n",
    "                        width_coef=1.6,\n",
    "                        depth_coef=2.2,\n",
    "                        scale=456/224,\n",
    "                        dropout=0.4,\n",
    "                        se_scale=4)\n",
    "\n",
    "def efficientnet_b6(num_classes=5):\n",
    "    return EfficientNet(num_classes=num_classes,\n",
    "                        width_coef=1.8,\n",
    "                        depth_coef=2.6,\n",
    "                        scale=528/224,\n",
    "                        dropout=0.5,\n",
    "                        se_scale=4)\n",
    "\n",
    "def efficientnet_b7(num_classes=5):\n",
    "    return EfficientNet(num_classes=num_classes,\n",
    "                        width_coef=2.0,\n",
    "                        depth_coef=3.1,\n",
    "                        scale=600/224,\n",
    "                        dropout=0.5,\n",
    "                        se_scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = 'dataset'\n",
    "\n",
    "# train_dir = os.path.join(data_dir, 'train')\n",
    "# valid_dir = os.path.join(data_dir, 'validation')\n",
    "# test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# train_dir = os.path.join('DATA_IMAGE_2/trains/*/')\n",
    "# valid_dir = os.path.join('DATA_IMAGE_2_resize/validation/*/')\n",
    "# test_dir = os.path.join('DATA_IMAGE_2_resize/test/')\n",
    "\n",
    "train_dir = os.path.join('DATA_CROPPED_resize/train/*/')\n",
    "valid_dir = os.path.join('DATA_CROPPED_resize/validation/*/')\n",
    "test_dir = os.path.join('DATA_CROPPED_resize/test/')\n",
    "\n",
    "train_dataset = CustomDatasetCropped(train_dir, transform = train_transforms)\n",
    "valid_dataset = CustomDatasetCropped(valid_dir, transform = test_transforms)\n",
    "test_dataset = CustomDatasetCropped(test_dir, mode = 'Test', transform = test_transforms)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "\n",
    "# train_dataset = CustomDataset(train_dir, transform = train_transforms)\n",
    "# valid_dataset = CustomDataset(valid_dir, transform = test_transforms)\n",
    "# test_dataset = CustomDataset(test_dir, mode = 'Test', transform = test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = True)\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                          batch_size = 16,\n",
    "                          shuffle = True)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size = 1,\n",
    "                         shuffle = False)\n",
    "\n",
    "# GPU \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#EfficientNet\n",
    "model_ft = efficientnet_b2()\n",
    "num_ftrs = 1408\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 512)\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# # # Inception\n",
    "# model_ft = models.efficientnet_b7()\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# print(model_ft)\n",
    "print(\"Model loaded\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.001)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 5, gamma = 0.85)\n",
    "# exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=5, eta_min=0.001)\n",
    "# exp_lr_scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer_ft,\n",
    "#                                                             T_0=5,\n",
    "#                                                             T_mult=1,\n",
    "#                                                             eta_min=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "print(\"Training start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --Model Save--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lite_save(state, epoch, save_dir, model):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    target_path = f'{save_dir}/{state}.path.tar'\n",
    "    \n",
    "    with open(target_path, \"wb\") as f:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict':model.state_dict(),}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'efficientnet_b2_v1'\n",
    "SAVE_PATH = f'weights/{MODEL_NAME}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial LRDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class PolynomialLRDecay(_LRScheduler):\n",
    "    \"\"\"Polynomial learning rate decay until step reach to max_decay_step\n",
    "    \n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        max_decay_steps: after this step, we stop decreasing learning rate\n",
    "        end_learning_rate: scheduler stoping learning rate decay, value of learning rate must be this value\n",
    "        power: The power of the polynomial.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, optimizer, max_decay_steps, end_learning_rate=0.0001, power=1.0):\n",
    "        if max_decay_steps <= 1.:\n",
    "            raise ValueError('max_decay_steps should be greater than 1.')\n",
    "        self.max_decay_steps = max_decay_steps\n",
    "        self.end_learning_rate = end_learning_rate\n",
    "        self.power = power\n",
    "        self.last_step = 0\n",
    "        super().__init__(optimizer)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if self.last_step > self.max_decay_steps:\n",
    "            return [self.end_learning_rate for _ in self.base_lrs]\n",
    "\n",
    "        return [(base_lr - self.end_learning_rate) * \n",
    "                ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                self.end_learning_rate for base_lr in self.base_lrs]\n",
    "    \n",
    "    def step(self, step=None):\n",
    "        if step is None:\n",
    "            step = self.last_step + 1\n",
    "        self.last_step = step if step != 0 else 1\n",
    "        if self.last_step <= self.max_decay_steps:\n",
    "            decay_lrs = [(base_lr - self.end_learning_rate) * \n",
    "                         ((1 - self.last_step / self.max_decay_steps) ** (self.power)) + \n",
    "                         self.end_learning_rate for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, decay_lrs):\n",
    "                param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_steps = (len(train_dataset) // 16 + 1) * num_epochs ## Batch _size\n",
    "\n",
    "plr = PolynomialLRDecay(optimizer_ft,\n",
    "                        max_decay_steps=decay_steps,\n",
    "                        end_learning_rate=0.0001,\n",
    "                        power=9.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    if len(targets.shape) == 1:\n",
    "        return F.cross_entropy(outputs, targets)\n",
    "    else:\n",
    "        return torch.mean(torch.sum(-targets * F.log_softmax(outputs, dim=1), dim=1))\n",
    "\n",
    "def label_smooth_criterion(outputs, targets, epsilon=0.1):\n",
    "    num_classes = outputs.shape[1]\n",
    "    onehot = F.one_hot(targets, num_classes).to(dtype=torch.float, device=device)\n",
    "    targets = (1 - epsilon) * onehot + torch.ones(onehot.shape).to(\n",
    "        device\n",
    "    ) * epsilon / num_classes\n",
    "    return loss_fn(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bae\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, train_loader, valid_loader):\n",
    "    best_acc = 0\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_correct = 0\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_losses = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        for train_x, train_y in tqdm.tqdm(train_loader, total=len(train_loader)):\n",
    "            model.train()\n",
    "           \n",
    "            train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             # Mixup\n",
    "#             train_x, train_y_a, train_y_b, lam = mixup_data(train_x, train_y)\n",
    "#             train_x, train_y_a, train_y_b = map(Variable, (train_x, train_y_a, train_y_b))\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = model(train_x)\n",
    "                _, preds = torch.max(pred, 1)\n",
    "                loss = criterion(pred, train_y)\n",
    "#                 loss = mixup_criterion(label_smooth_criterion, pred, train_y_a, train_y_b, lam)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                train_correct += torch.sum(preds == train_y)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            scheduler.step()\n",
    "\n",
    "        plr.step()\n",
    "        \n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_correct = 0\n",
    "\n",
    "        for valid_x, valid_y in tqdm.tqdm(valid_loader, total=len(valid_loader)):\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_x, valid_y = valid_x.to(device), valid_y.to(device)\n",
    "                pred = model(valid_x)\n",
    "                loss = criterion(pred, valid_y)\n",
    "            valid_loss += loss.item()\n",
    "            pred = model(train_x)\n",
    "            _, preds = torch.max(pred, 1)\n",
    "            valid_correct += torch.sum(preds == train_y)\n",
    "        train_acc = train_correct/len(train_loader.dataset)\n",
    "        valid_acc = valid_correct/len(valid_loader.dataset)\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            best_acc = valid_acc\n",
    "            \n",
    "            lite_save('best', epoch, SAVE_PATH, model)\n",
    "        lite_save('best', epoch, SAVE_PATH, model)\n",
    "        \n",
    "        print(f'{time.time() - start:.3f}sec : [Epoch {epoch+1}/{num_epochs} -> \\\n",
    "              train loss: {train_loss/len(train_loader):.4f},\\\n",
    "              valid loss: {valid_loss/len(valid_loader):.4f}')\n",
    "        \n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_losses.append(valid_loss/len(valid_loader))\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_correct = 0\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft,\n",
    "                       label_smooth_criterion,\n",
    "                       optimizer_ft,\n",
    "                       exp_lr_scheduler,\n",
    "                       num_epochs,\n",
    "                       train_loader,\n",
    "                       valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ttach as tta\n",
    "\n",
    "# Five crop_transform\n",
    "# model_ft = tta.ClassificationTTAWrapper(model_ft, tta.aliases.)\n",
    "\n",
    "model_ft = models.resnet152()\n",
    "model_ft.load_state_dict(torch.load('./weights/efficientnet_b7_v1/best.path.tar')['model_state_dict'],strict=False)\n",
    "model_ft.cuda()\n",
    "# print('model loaded')\n",
    "\n",
    "# inference code\n",
    "f = open('배류나이 배류배류_test_result.csv', 'w', encoding ='utf-8', newline = '')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['case', 'Predicted Severity', 'Inference time(ms)'])\n",
    "with torch.no_grad():\n",
    "    model_ft.eval()\n",
    "    correct = 0\n",
    "    losses = 0\n",
    "\n",
    "    for img, files in test_loader:\n",
    "        img = img.to(device)\n",
    "        start = time.time()\n",
    "        pred = model_ft(img)\n",
    "        _, preds = torch.max(pred, 1)\n",
    "        end = time.time()\n",
    "        preds = preds.cpu().numpy()[0]\n",
    "\n",
    "        wr.writerow([os.path.basename(files[0])[:-4], class_names[preds], (end - start) * 1000])\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
