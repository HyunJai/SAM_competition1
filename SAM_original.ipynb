{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import csv\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time, os, json\n",
    "\n",
    "class_names = ['Normal', 'Almost Clear', 'Mild', 'Moderate', 'Severe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, mode = 'Training', transform = None):\n",
    "        self.root_dir = root_dir\n",
    "        self.img_path = glob.glob(root_dir + '/*/crop/*.jpg')\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_path[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'Test':\n",
    "            return img, self.img_path[idx]\n",
    "        else:\n",
    "            dir_name = os.path.dirname(self.img_path[idx])\n",
    "            file_name = os.path.basename(self.img_path[idx])\n",
    "            json_full_path = os.path.join(os.path.join(dir_name[:-4], 'metadata'), file_name[:-4] + '.json')\n",
    "            data = json.load(open(json_full_path))\n",
    "            if 'iga_grade' in data['annotations'][0]['clinical_info']:\n",
    "                grade = class_names.index(data['annotations'][0]['clinical_info']['iga_grade'])\n",
    "            else:\n",
    "                grade = 0\n",
    "            return img, grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, train_loader, valid_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    train_correct = 0\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_losses = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        for train_x, train_y in train_loader:\n",
    "            model.train()\n",
    "            train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(train_x)\n",
    "            _, preds = torch.max(pred, 1)\n",
    "            loss = criterion(pred, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_correct += torch.sum(preds == train_y)\n",
    "            scheduler.step()\n",
    "\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        valid_correct = 0\n",
    "\n",
    "        for valid_x, valid_y in valid_loader:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                valid_x, valid_y = valid_x.to(device), valid_y.to(device)\n",
    "                pred = model(valid_x)\n",
    "                loss = criterion(pred, valid_y)\n",
    "            valid_loss += loss.item()\n",
    "            pred = model(train_x)\n",
    "            _, preds = torch.max(pred, 1)\n",
    "            valid_correct += torch.sum(preds == train_y)\n",
    "        train_acc = train_correct/len(train_loader.dataset)\n",
    "        valid_acc = valid_correct/len(valid_loader.dataset)\n",
    "        print(f'{time.time() - start:.3f}sec : [Epoch {epoch+1}/{num_epochs} -> \\\n",
    "              train loss: {train_loss/len(train_loader):.4f}, train acc: {train_acc*100:.3f}%/ \\\n",
    "              valid loss: {valid_loss/len(valid_loader):.4f}, valid acc: {valid_acc*100:.3f}%')\n",
    "        \n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        train_accuracies.append(train_acc)\n",
    "        valid_losses.append(valid_loss/len(valid_loader))\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_correct = 0\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset'\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "valid_dir = os.path.join(data_dir, 'validation')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "print(train_dir)\n",
    "\n",
    "train_dataset = CustomDataset(train_dir, transform = train_transforms)\n",
    "valid_dataset = CustomDataset(valid_dir, transform = test_transforms)\n",
    "test_dataset = CustomDataset(test_dir, mode = 'Test', transform = test_transforms)\n",
    "print(\"train_dataset = \", len(train_dataset))\n",
    "print(\"valid_dataset = \", len(valid_dataset))\n",
    "print(\"test_dataset = \", len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\n",
    "print(\"train_loader = \", len(train_loader))\n",
    "print(\"valid_loader = \", len(valid_loader))\n",
    "print(\"test_loader = \", len(test_loader))\n",
    "\n",
    "# GPU \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ft = models.resnet18(pretrained = True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "print(\"Model loaded\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.AdamW(model_ft.parameters(), lr = 0.0001)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 7, gamma = 0.1)\n",
    "\n",
    "num_epochs = 50\n",
    "print(\"Training start\")\n",
    "\n",
    "\n",
    "#     # inference code\n",
    "#     f = open('배류나이 배류배류_test_result.csv', 'w', encoding ='utf-8', newline = '')\n",
    "#     wr = csv.writer(f)\n",
    "#     wr.writerow(['case', 'Predicted Severity', 'Inference time(ms)'])\n",
    "#     with torch.no_grad():\n",
    "#         model_ft.eval()\n",
    "#         correct = 0\n",
    "#         losses = 0\n",
    "\n",
    "#         for img, files in test_loader:\n",
    "#             img = img.to(device)\n",
    "#             start = time.time()\n",
    "#             pred = model_ft(img)\n",
    "#             _, preds = torch.max(pred, 1)\n",
    "#             end = time.time()\n",
    "#             preds = preds.cpu().numpy()[0]\n",
    "\n",
    "#             wr.writerow([os.path.basename(files[0][:-4], class_names[preds], (end - start) * 1000)])\n",
    "\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs, train_loader, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
